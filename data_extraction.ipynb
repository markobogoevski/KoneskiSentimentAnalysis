{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "appreciated-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import sentiwordnet\n",
    "from nltk.util import ngrams\n",
    "stop_words = set(stopwords.words('english')) \n",
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "detected-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(var):\n",
    "    flat = [item for sublist in var for item in sublist]\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./Results/MK', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "altered-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/Koneski_final_finished_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "exact-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Godina_od</th>\n",
       "      <th>Godina_do</th>\n",
       "      <th>Zbirka</th>\n",
       "      <th>Zbirka_broj</th>\n",
       "      <th>Podzbirka</th>\n",
       "      <th>Podzbirka_broj</th>\n",
       "      <th>Pesna_Broj</th>\n",
       "      <th>Pesna_Ime</th>\n",
       "      <th>Pesna</th>\n",
       "      <th>Stih_Broj</th>\n",
       "      <th>Stih</th>\n",
       "      <th>Pesna_eng</th>\n",
       "      <th>Stih_eng</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9379</th>\n",
       "      <td>9379</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993</td>\n",
       "      <td>ЦРН ОВЕН (1993)</td>\n",
       "      <td>7</td>\n",
       "      <td>ОTPОР</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...</td>\n",
       "      <td>6</td>\n",
       "      <td>Како да се поништи ужасот</td>\n",
       "      <td>OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...</td>\n",
       "      <td>How to undo the horror</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9380</th>\n",
       "      <td>9380</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993</td>\n",
       "      <td>ЦРН ОВЕН (1993)</td>\n",
       "      <td>7</td>\n",
       "      <td>ОTPОР</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...</td>\n",
       "      <td>7</td>\n",
       "      <td>со тоа што човек</td>\n",
       "      <td>OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...</td>\n",
       "      <td>by being a man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9381</th>\n",
       "      <td>9381</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993</td>\n",
       "      <td>ЦРН ОВЕН (1993)</td>\n",
       "      <td>7</td>\n",
       "      <td>ОTPОР</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...</td>\n",
       "      <td>8</td>\n",
       "      <td>не може да го сфати?</td>\n",
       "      <td>OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...</td>\n",
       "      <td>can not understand it?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9382</th>\n",
       "      <td>9382</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993</td>\n",
       "      <td>ЦРН ОВЕН (1993)</td>\n",
       "      <td>7</td>\n",
       "      <td>ОTPОР</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...</td>\n",
       "      <td>9</td>\n",
       "      <td>Проклета слабост да се зборне.</td>\n",
       "      <td>OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...</td>\n",
       "      <td>Damn weakness to speak.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>9383</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993</td>\n",
       "      <td>ЦРН ОВЕН (1993)</td>\n",
       "      <td>7</td>\n",
       "      <td>ОTPОР</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993</td>\n",
       "      <td>СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...</td>\n",
       "      <td>10</td>\n",
       "      <td>Поживинченост, ако молчиш.</td>\n",
       "      <td>OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...</td>\n",
       "      <td>Liveliness, if you are silent.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Godina_od  Godina_do           Zbirka  Zbirka_broj  \\\n",
       "9379        9379       1993       1993  ЦРН ОВЕН (1993)            7   \n",
       "9380        9380       1993       1993  ЦРН ОВЕН (1993)            7   \n",
       "9381        9381       1993       1993  ЦРН ОВЕН (1993)            7   \n",
       "9382        9382       1993       1993  ЦРН ОВЕН (1993)            7   \n",
       "9383        9383       1993       1993  ЦРН ОВЕН (1993)            7   \n",
       "\n",
       "     Podzbirka  Podzbirka_broj  Pesna_Broj                 Pesna_Ime  \\\n",
       "9379     ОTPОР               1          36  СПРОТИ СВЕТИ АТАНАС 1993   \n",
       "9380     ОTPОР               1          36  СПРОТИ СВЕТИ АТАНАС 1993   \n",
       "9381     ОTPОР               1          36  СПРОТИ СВЕТИ АТАНАС 1993   \n",
       "9382     ОTPОР               1          36  СПРОТИ СВЕТИ АТАНАС 1993   \n",
       "9383     ОTPОР               1          36  СПРОТИ СВЕТИ АТАНАС 1993   \n",
       "\n",
       "                                                  Pesna  Stih_Broj  \\\n",
       "9379  СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...          6   \n",
       "9380  СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...          7   \n",
       "9381  СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...          8   \n",
       "9382  СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...          9   \n",
       "9383  СПРОТИ СВЕТИ АТАНАС 1993\\nЗимски дену,\\nми нос...         10   \n",
       "\n",
       "                                Stih  \\\n",
       "9379       Како да се поништи ужасот   \n",
       "9380                со тоа што човек   \n",
       "9381            не може да го сфати?   \n",
       "9382  Проклета слабост да се зборне.   \n",
       "9383      Поживинченост, ако молчиш.   \n",
       "\n",
       "                                              Pesna_eng  \\\n",
       "9379  OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...   \n",
       "9380  OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...   \n",
       "9381  OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...   \n",
       "9382  OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...   \n",
       "9383  OPPOSITE SAINT ATANAS 1993\\nWinter day,\\nyou b...   \n",
       "\n",
       "                            Stih_eng Unnamed: 14 Unnamed: 15  \n",
       "9379          How to undo the horror         NaN         NaN  \n",
       "9380                  by being a man         NaN         NaN  \n",
       "9381          can not understand it?         NaN         NaN  \n",
       "9382         Damn weakness to speak.         NaN         NaN  \n",
       "9383  Liveliness, if you are silent.         NaN         NaN  "
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "shaped-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stih_in_pesna_count = df.groupby(['Pesna_Broj', 'Zbirka_broj'], as_index=False).last()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-interpretation",
   "metadata": {},
   "source": [
    "## Number of stihs in pesna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "macro-bargain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pesna_Broj</th>\n",
       "      <th>Zbirka_broj</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Godina_od</th>\n",
       "      <th>Godina_do</th>\n",
       "      <th>Zbirka</th>\n",
       "      <th>Podzbirka</th>\n",
       "      <th>Podzbirka_broj</th>\n",
       "      <th>Pesna_Ime</th>\n",
       "      <th>Pesna</th>\n",
       "      <th>Stih_Broj</th>\n",
       "      <th>Stih</th>\n",
       "      <th>Pesna_eng</th>\n",
       "      <th>Stih_eng</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5126</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>ЧЕШМИТЕ (1984)</td>\n",
       "      <td>ДОЈРАНСКИ ВЕТРИШТА</td>\n",
       "      <td>2</td>\n",
       "      <td>АНА</td>\n",
       "      <td>АНА\\nНа сpоменоt на Ана Пенинgtон\\nТаа беше за...</td>\n",
       "      <td>16</td>\n",
       "      <td>Но секој носел своја судбина.</td>\n",
       "      <td>ANA\\nIn memory of Anne Pennington\\nShe was for...</td>\n",
       "      <td>But everyone had their own destiny.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5430</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987</td>\n",
       "      <td>ПОСЛАНИЕ (1987)</td>\n",
       "      <td>ПОСЛАНИЕ</td>\n",
       "      <td>1</td>\n",
       "      <td>ПОЕЗИЈО</td>\n",
       "      <td>ПОЕЗИЈО\\nПоезијо,\\nми отвораш пат во староста,...</td>\n",
       "      <td>12</td>\n",
       "      <td>само со едното и другото.</td>\n",
       "      <td>POETRY\\nPoetry,\\nyou open the way for me in ol...</td>\n",
       "      <td>only with both.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6269</td>\n",
       "      <td>1988</td>\n",
       "      <td>1988</td>\n",
       "      <td>ЦРКВА (1988)</td>\n",
       "      <td>ЦРКВА (1988)</td>\n",
       "      <td>1</td>\n",
       "      <td>ЦРКВА</td>\n",
       "      <td>ЦРКВА\\nНека е проклет часот кога ми кажаа\\nдек...</td>\n",
       "      <td>123</td>\n",
       "      <td>твоите свети камења.</td>\n",
       "      <td>CHURCH\\nCursed be the hour when they told me\\n...</td>\n",
       "      <td>your sacred stones.</td>\n",
       "      <td>The old men jump to the old men</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7320</td>\n",
       "      <td>1989</td>\n",
       "      <td>1989</td>\n",
       "      <td>ЗЛАТОВРВ (1989)</td>\n",
       "      <td>СКРЖАВИ PЕСНИ</td>\n",
       "      <td>4</td>\n",
       "      <td>ГЛЕДАЊЕ ВО ФИЛЏАН</td>\n",
       "      <td>ГЛЕДАЊЕ ВО ФИЛЏАН\\nЕве една стара жена\\nзабрад...</td>\n",
       "      <td>14</td>\n",
       "      <td>на твојот живот.</td>\n",
       "      <td>LOOKING IN A CUP\\nHere is an old woman\\nlined ...</td>\n",
       "      <td>sitting by the window</td>\n",
       "      <td>roared in the dark</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8151</td>\n",
       "      <td>1989</td>\n",
       "      <td>1989</td>\n",
       "      <td>СЕИЗМОГРАФ (1989)</td>\n",
       "      <td>ЗАНАЕT</td>\n",
       "      <td>3</td>\n",
       "      <td>МАКЕДОНСКИ ПОЕТИ</td>\n",
       "      <td>МАКЕДОНСКИ ПОЕТИ\\nКаква судбина!\\nДа ти се чин...</td>\n",
       "      <td>11</td>\n",
       "      <td>исполнето.</td>\n",
       "      <td>MACEDONIAN POETS\\nWhat a destiny!\\nYes, it see...</td>\n",
       "      <td>fulfilled.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pesna_Broj  Zbirka_broj  Unnamed: 0  Godina_od  Godina_do  \\\n",
       "0           1            1        5126       1984       1984   \n",
       "1           1            2        5430       1987       1987   \n",
       "2           1            3        6269       1988       1988   \n",
       "3           1            4        7320       1989       1989   \n",
       "4           1            5        8151       1989       1989   \n",
       "\n",
       "              Zbirka           Podzbirka  Podzbirka_broj          Pesna_Ime  \\\n",
       "0     ЧЕШМИТЕ (1984)  ДОЈРАНСКИ ВЕТРИШТА               2                АНА   \n",
       "1    ПОСЛАНИЕ (1987)            ПОСЛАНИЕ               1            ПОЕЗИЈО   \n",
       "2       ЦРКВА (1988)        ЦРКВА (1988)               1              ЦРКВА   \n",
       "3    ЗЛАТОВРВ (1989)       СКРЖАВИ PЕСНИ               4  ГЛЕДАЊЕ ВО ФИЛЏАН   \n",
       "4  СЕИЗМОГРАФ (1989)              ЗАНАЕT               3   МАКЕДОНСКИ ПОЕТИ   \n",
       "\n",
       "                                               Pesna  Stih_Broj  \\\n",
       "0  АНА\\nНа сpоменоt на Ана Пенинgtон\\nТаа беше за...         16   \n",
       "1  ПОЕЗИЈО\\nПоезијо,\\nми отвораш пат во староста,...         12   \n",
       "2  ЦРКВА\\nНека е проклет часот кога ми кажаа\\nдек...        123   \n",
       "3  ГЛЕДАЊЕ ВО ФИЛЏАН\\nЕве една стара жена\\nзабрад...         14   \n",
       "4  МАКЕДОНСКИ ПОЕТИ\\nКаква судбина!\\nДа ти се чин...         11   \n",
       "\n",
       "                            Stih  \\\n",
       "0  Но секој носел своја судбина.   \n",
       "1      само со едното и другото.   \n",
       "2           твоите свети камења.   \n",
       "3               на твојот живот.   \n",
       "4                     исполнето.   \n",
       "\n",
       "                                           Pesna_eng  \\\n",
       "0  ANA\\nIn memory of Anne Pennington\\nShe was for...   \n",
       "1  POETRY\\nPoetry,\\nyou open the way for me in ol...   \n",
       "2  CHURCH\\nCursed be the hour when they told me\\n...   \n",
       "3  LOOKING IN A CUP\\nHere is an old woman\\nlined ...   \n",
       "4  MACEDONIAN POETS\\nWhat a destiny!\\nYes, it see...   \n",
       "\n",
       "                              Stih_eng                      Unnamed: 14  \\\n",
       "0  But everyone had their own destiny.                             None   \n",
       "1                      only with both.                             None   \n",
       "2                  your sacred stones.  The old men jump to the old men   \n",
       "3                sitting by the window               roared in the dark   \n",
       "4                           fulfilled.                             None   \n",
       "\n",
       "  Unnamed: 15  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  "
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stih_in_pesna_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "seven-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stih_in_pesna_count.to_csv('./Results/number_of_stih_in_pesna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "worthy-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesni = df['Pesna_eng']\n",
    "stihovi = df['Stih_eng']\n",
    "godina_od = df['Godina_od']\n",
    "godina_do = df['Godina_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "legislative-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesni_list = set(pesni.to_list())\n",
    "pesni_list = (list(pesni_list))\n",
    "pesni_list = [x for x in pesni_list if str(x) != 'nan']\n",
    "stihovi_list = stihovi.to_list()\n",
    "godina_od_list = godina_od.to_list()\n",
    "godina_do_list = godina_do.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "searching-decrease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9384"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(godina_do_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-diploma",
   "metadata": {},
   "source": [
    "# Stihovi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-surprise",
   "metadata": {},
   "source": [
    "## Word count with lematization and removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "annual-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "stihovi_cleaned = []\n",
    "stihovi_sentences = []\n",
    "ids = []\n",
    "for i, stih in enumerate(stihovi_list):\n",
    "    if type(stih) is not float and type(stih) is not int:\n",
    "        stih = stih.lower()\n",
    "        stih = nltk.word_tokenize(stih)\n",
    "        stih = [re.sub(r'[^\\w\\s]','',word) for word in stih]\n",
    "        stih = [word for word in stih if not word in stop_words]\n",
    "        stih = [word for word in stih if word.isalpha()]\n",
    "        stih = [lemmatizer.lemmatize(each_word) for each_word in stih]\n",
    "        if len(stih) == 0:\n",
    "            continue\n",
    "        stihovi_sentences.append(' '.join(stih))\n",
    "        stihovi_cleaned.append(stih)\n",
    "        ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "about-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "godina_od_list = df.iloc[ids, 1]\n",
    "godina_do_list = df.iloc[ids, 2]\n",
    "ime_na_pesni = df.iloc[ids, :]['Pesna_Ime']\n",
    "ime_na_zbirka = df.iloc[ids, :]['Zbirka']\n",
    "ime_na_podzbirka = df.iloc[ids, :]['Podzbirka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "centered-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame({'sentence': stihovi_sentences, \n",
    "                             'year_from': godina_od_list, \n",
    "                             'year_to': godina_do_list, \n",
    "                             'song_name':ime_na_pesni, \n",
    "                             'zbirka_name':ime_na_zbirka, \n",
    "                             'podzbirka_name':ime_na_podzbirka})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "furnished-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('./Results/sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-tribe",
   "metadata": {},
   "source": [
    "### Average words per stih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "textile-sending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.89791916330755\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "for stih in stihovi_cleaned:\n",
    "    number_of_words += len(stih)\n",
    "print(number_of_words/len(stihovi_cleaned))\n",
    "stihovi_cleaned_flat = flat_list(stihovi_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "devoted-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "stihovi_cleaned_flat = flat_list(stihovi_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "imposed-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count = Counter(stihovi_cleaned_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "drawn-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df = pd.DataFrame(stih_count.most_common())\n",
    "stih_count_df.columns = ['words', 'count']\n",
    "stih_count_df.to_csv('./Results/stih_word_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "governmental-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df_10 = stih_count_df[stih_count_df['count'] > 10]\n",
    "stih_count_df_10.to_csv('./Results/stih_word_count_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-injection",
   "metadata": {},
   "source": [
    "## Word count without lematization and removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "meaningful-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "stihovi_cleaned = []\n",
    "stihovi_sentences = []\n",
    "ids = []\n",
    "for i, stih in enumerate(stihovi_list):\n",
    "    if type(stih) is not float and type(stih) is not int:\n",
    "        stih = stih.lower()\n",
    "        stih = nltk.word_tokenize(stih)\n",
    "        stih = [re.sub(r'[^\\w\\s]','',word) for word in stih]\n",
    "        stih = [word for word in stih if not word in stop_words]\n",
    "        stih = [word for word in stih if word.isalpha()]\n",
    "        if len(stih) == 0:\n",
    "            continue\n",
    "        stihovi_sentences.append(' '.join(stih))\n",
    "        stihovi_cleaned.append(stih)\n",
    "        ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "vertical-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "godina_od_list = df.iloc[ids, 1]\n",
    "godina_do_list = df.iloc[ids, 2]\n",
    "ime_na_pesni = df.iloc[ids, :]['Pesna_Ime']\n",
    "ime_na_zbirka = df.iloc[ids, :]['Zbirka']\n",
    "ime_na_podzbirka = df.iloc[ids, :]['Podzbirka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "persistent-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame({'sentence': stihovi_sentences, \n",
    "                             'year_from': godina_od_list, \n",
    "                             'year_to': godina_do_list, \n",
    "                             'song_name':ime_na_pesni, \n",
    "                             'zbirka_name':ime_na_zbirka, \n",
    "                             'podzbirka_name':ime_na_podzbirka})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "behavioral-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('./Results/sentences_without_lem_without_stop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-brooklyn",
   "metadata": {},
   "source": [
    "### Average words per stih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "innocent-soldier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.89791916330755\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "for stih in stihovi_cleaned:\n",
    "    number_of_words += len(stih)\n",
    "print(number_of_words/len(stihovi_cleaned))\n",
    "stihovi_cleaned_flat = flat_list(stihovi_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "muslim-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "stihovi_cleaned_flat = flat_list(stihovi_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "absolute-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count = Counter(stihovi_cleaned_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "introductory-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df = pd.DataFrame(stih_count.most_common())\n",
    "stih_count_df.columns = ['words', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "blocked-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df.to_csv('./Results/stih_word_count_without_lem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "virtual-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df_10 = stih_count_df[stih_count_df['count'] > 10]\n",
    "stih_count_df_10.to_csv('./Results/stih_word_count_without_lem_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-jefferson",
   "metadata": {},
   "source": [
    "## Word count without lematization and without removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "strange-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "stihovi_cleaned = []\n",
    "stihovi_sentences = []\n",
    "ids = []\n",
    "for i, stih in enumerate(stihovi_list):\n",
    "    if type(stih) is not float and type(stih) is not int:\n",
    "        stih = stih.lower()\n",
    "        stih = nltk.word_tokenize(stih)\n",
    "        stih = [re.sub(r'[^\\w\\s]','',word) for word in stih]\n",
    "        stih = [word for word in stih if word.isalpha()]\n",
    "        if len(stih) == 0:\n",
    "            continue\n",
    "        stihovi_sentences.append(' '.join(stih))\n",
    "        stihovi_cleaned.append(stih)\n",
    "        ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "controlled-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "godina_od_list = df.iloc[ids, 1]\n",
    "godina_do_list = df.iloc[ids, 2]\n",
    "ime_na_pesni = df.iloc[ids, :]['Pesna_Ime']\n",
    "ime_na_zbirka = df.iloc[ids, :]['Zbirka']\n",
    "ime_na_podzbirka = df.iloc[ids, :]['Podzbirka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "irish-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame({'sentence': stihovi_sentences, \n",
    "                             'year_from': godina_od_list, \n",
    "                             'year_to': godina_do_list, \n",
    "                             'song_name':ime_na_pesni, \n",
    "                             'zbirka_name':ime_na_zbirka, \n",
    "                             'podzbirka_name':ime_na_podzbirka})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "ongoing-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('./Results/sentences_without_lem_with_stopwords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-placement",
   "metadata": {},
   "source": [
    "### Average words per stih "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "strategic-technology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "for stih in stihovi_cleaned:\n",
    "    number_of_words += len(stih)\n",
    "avg_words_per_stih = round(number_of_words/len(stihovi_cleaned))\n",
    "print(round(number_of_words/len(stihovi_cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "packed-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "stihovi_cleaned_flat = flat_list(stihovi_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "successful-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count = Counter(stihovi_cleaned_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "wrong-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df = pd.DataFrame(stih_count.most_common())\n",
    "stih_count_df.columns = ['words', 'count']\n",
    "stih_count_df.to_csv('./Results/stih_word_count_without_lem_with_stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "working-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_count_df_10 = stih_count_df[stih_count_df['count'] > 10]\n",
    "stih_count_df_10.to_csv('./Results/stih_word_count_lem_with_stopwords_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-statistics",
   "metadata": {},
   "source": [
    "# Pesni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-desert",
   "metadata": {},
   "source": [
    "## Word count with lematization and removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "moral-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesni_cleaned = []\n",
    "pesni_sentences = []\n",
    "ids = []\n",
    "for i, pesna in enumerate(pesni_list):\n",
    "    if type(pesna) is not float:\n",
    "        pesna = pesna.lower()\n",
    "        pesna = nltk.word_tokenize(pesna)\n",
    "        pesna = [re.sub(r'[^\\w\\s]','',word) for word in pesna]\n",
    "        pesna = [word for word in pesna if not word in stop_words]\n",
    "        pesna = [word for word in pesna if word.isalpha()]\n",
    "        pesna = [lemmatizer.lemmatize(each_word) for each_word in pesna]\n",
    "        if len(pesna) == 0:\n",
    "            continue\n",
    "        pesni_sentences.append(' '.join(pesna))\n",
    "        pesni_cleaned.append(pesna)\n",
    "        ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "cubic-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "godina_od_list = df.iloc[ids, 1]\n",
    "godina_do_list = df.iloc[ids, 2]\n",
    "ime_na_pesni = df.iloc[ids, :]['Pesna_Ime']\n",
    "ime_na_zbirka = df.iloc[ids, :]['Zbirka']\n",
    "ime_na_podzbirka = df.iloc[ids, :]['Podzbirka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "governmental-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame({'pesna': pesni_sentences, \n",
    "                             'year_from': godina_od_list, \n",
    "                             'year_to': godina_do_list, \n",
    "                             'song_name':ime_na_pesni, \n",
    "                             'zbirka_name':ime_na_zbirka, \n",
    "                             'podzbirka_name':ime_na_podzbirka})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "separated-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('./Results/pesni_lem_without_stopwords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-doubt",
   "metadata": {},
   "source": [
    "### Average words per pesna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "hispanic-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.4367816091954\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "pesna_len = []\n",
    "for pesna in pesni_cleaned:\n",
    "    number_of_words += len(pesna)\n",
    "    pesna_len.append(len(pesna))\n",
    "print(number_of_words/len(pesni_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "traditional-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter = Counter(pesna_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "abroad-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df = pd.DataFrame.from_dict(pesna_len_counter, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "equivalent-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df = pesna_len_counter_df.rename(columns={'index':'words_in_pesna', 0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "toxic-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df.to_csv('./Results/word_count_in_pesna_lem_without_stop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-chapter",
   "metadata": {},
   "source": [
    "## Word count without lematization and removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "waiting-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesni_cleaned = []\n",
    "pesni_sentences = []\n",
    "ids = []\n",
    "for i, pesna in enumerate(pesni_list):\n",
    "    if type(pesna) is not float:\n",
    "        pesna = pesna.lower()\n",
    "        pesna = nltk.word_tokenize(pesna)\n",
    "        pesna = [re.sub(r'[^\\w\\s]','',word) for word in pesna]\n",
    "        pesna = [word for word in pesna if not word in stop_words]\n",
    "        pesna = [word for word in pesna if word.isalpha()]\n",
    "        if len(pesna) == 0:\n",
    "            continue\n",
    "        pesni_sentences.append(' '.join(pesna))\n",
    "        pesni_cleaned.append(pesna)\n",
    "        ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "alpha-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "godina_od_list = df.iloc[ids, 1]\n",
    "godina_do_list = df.iloc[ids, 2]\n",
    "ime_na_pesni = df.iloc[ids, :]['Pesna_Ime']\n",
    "ime_na_zbirka = df.iloc[ids, :]['Zbirka']\n",
    "ime_na_podzbirka = df.iloc[ids, :]['Podzbirka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "based-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame({'pesna': pesni_sentences, \n",
    "                             'year_from': godina_od_list, \n",
    "                             'year_to': godina_do_list, \n",
    "                             'song_name':ime_na_pesni, \n",
    "                             'zbirka_name':ime_na_zbirka, \n",
    "                             'podzbirka_name':ime_na_podzbirka})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "committed-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('./Results/pesni_without_lem_without_stopwords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-induction",
   "metadata": {},
   "source": [
    "### Average words per pesna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "strategic-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.4367816091954\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "pesna_len = []\n",
    "for pesna in pesni_cleaned:\n",
    "    number_of_words += len(pesna)\n",
    "    pesna_len.append(len(pesna))\n",
    "print(number_of_words/len(pesni_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "universal-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter = Counter(pesna_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "thick-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df = pd.DataFrame.from_dict(pesna_len_counter, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "gorgeous-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df = pesna_len_counter_df.rename(columns={'index':'words_in_pesna', 0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "protective-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df.to_csv('./Results/word_count_in_pesna_no_lem_without_stop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-absolute",
   "metadata": {},
   "source": [
    "## Word count without lematization and without removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "approximate-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesni_cleaned = []\n",
    "pesni_sentences = []\n",
    "ids = []\n",
    "for i, pesna in enumerate(pesni_list):\n",
    "    if type(pesna) is not float:\n",
    "        pesna = pesna.lower()\n",
    "        pesna = nltk.word_tokenize(pesna)\n",
    "        pesna = [re.sub(r'[^\\w\\s]','',word) for word in pesna]\n",
    "        pesna = [word for word in pesna if word.isalpha()]\n",
    "        if len(pesna) == 0:\n",
    "            continue\n",
    "        pesni_sentences.append(' '.join(pesna))\n",
    "        pesni_cleaned.append(pesna)\n",
    "        ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "dress-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "godina_od_list = df.iloc[ids, 1]\n",
    "godina_do_list = df.iloc[ids, 2]\n",
    "ime_na_pesni = df.iloc[ids, :]['Pesna_Ime']\n",
    "ime_na_zbirka = df.iloc[ids, :]['Zbirka']\n",
    "ime_na_podzbirka = df.iloc[ids, :]['Podzbirka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "copyrighted-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame({'pesna': pesni_sentences, \n",
    "                             'year_from': godina_od_list, \n",
    "                             'year_to': godina_do_list, \n",
    "                             'song_name':ime_na_pesni, \n",
    "                             'zbirka_name':ime_na_zbirka, \n",
    "                             'podzbirka_name':ime_na_podzbirka})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "sweet-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('./Results/pesni_without_lem_with_stopwords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-collect",
   "metadata": {},
   "source": [
    "### Average words per pesna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "military-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "pesna_len = []\n",
    "for pesna in pesni_cleaned:\n",
    "    number_of_words += len(pesna)\n",
    "    pesna_len.append(len(pesna))\n",
    "avg_words_in_pesna = round(number_of_words/len(pesni_cleaned))\n",
    "print(round(number_of_words/len(pesni_cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "otherwise-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter = Counter(pesna_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "sorted-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df = pd.DataFrame.from_dict(pesna_len_counter, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "canadian-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df = pesna_len_counter_df.rename(columns={'index':'words_in_pesna', 0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "municipal-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesna_len_counter_df.to_csv('./Results/word_count_in_pesna_no_lem_with_stop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-access",
   "metadata": {},
   "source": [
    "### Average stih per pesna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "unlike-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "stih_in_pesna = df_stih_in_pesna_count['Stih_Broj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "royal-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import math\n",
    "avg_stih_in_pesna = round(statistics.mean(stih_in_pesna))\n",
    "print(avg_stih_in_pesna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-peripheral",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "incident-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Report.txt\", 'w') as report:\n",
    "    report.write(\"==========================REPORT=============================\")\n",
    "    report.write(f\"AVERAGE NUMBER OF STIHS IN PESNA {avg_stih_in_pesna}\")\n",
    "    report.write(f\"AVERAGE NUMBER OF ZBOROVI IN PESNA {avg_words_in_pesna}\")\n",
    "    report.write(f\"AVERAGE NUMBER OF ZBOROVI VO STIH {avg_words_per_stih}\")\n",
    "    report.write(\"==========================REPORT=============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
